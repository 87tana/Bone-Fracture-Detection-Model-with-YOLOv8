{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/87tana/YOLOv8-Bone-Fracture-Detection-Model/blob/main/EDA_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this notebook, i assess the label distribution, bounding box statistic, image dimension and data quality"
      ],
      "metadata": {
        "id": "P18oZxAuBCMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "\n",
        "# Navigate to the project directory\n",
        "%cd '/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/'\n",
        "\n",
        "\n",
        "# Define dataset path\n",
        "dataset_path = '/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection/Fraction_Detection_Dataset'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0z2800hBVao",
        "outputId": "5cda7392-eb62-4a59-ab77-7a589a499070"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive/Project_Experiments/Bone_Fraction_Detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install -q ultralytics torch torchvision opencv-python pillow matplotlib tqdm"
      ],
      "metadata": {
        "id": "nbnOcJ7VCDWL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "RR-60IcjCGeb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Dataset\n",
        "train_images_dir = os.path.join(dataset_path, 'train/images')\n",
        "train_labels_dir = os.path.join(dataset_path, 'train/labels')\n",
        "\n",
        "# list comprehensions to create a list for storing train images and labels respectively\n",
        "train_image_files = sorted([f for f in os.listdir(train_images_dir) if f.endswith('.jpg')])\n",
        "train_label_files = sorted([f for f in os.listdir(train_labels_dir) if f.endswith('.txt')])\n",
        "\n",
        "\n",
        "# Check if the number of images and labels match, ensure neither are empty, and verify consistency between image-label pairs.\n",
        "\n",
        "if len(train_image_files) != len(train_label_files):\n",
        "    print(\"Warning: Number of images and labels do not match.\")\n",
        "else:\n",
        "    print(\"Train Dataset is consistent.\")\n",
        "\n",
        "# Quick summary of train set\n",
        "print(f\"Number of train images: {len(train_image_files)}\")\n",
        "print(f\"Number of train labels: {len(train_label_files)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f6FSttvCWmC",
        "outputId": "9f73a0d9-f00e-4145-c768-01016352c37b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset is consistent.\n",
            "Number of train images: 3779\n",
            "Number of train labels: 3779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Valid Dataset\n",
        "validation_images_dir = os.path.join(dataset_path, 'valid/images')\n",
        "validation_labels_dir = os.path.join(dataset_path, 'valid/labels')\n",
        "\n",
        "# list comprehensions to create a list for storing valid images and labels respectively\n",
        "validation_image_files = sorted([f for f in os.listdir(validation_images_dir) if f.endswith('.jpg')])\n",
        "validation_label_files = sorted([f for f in os.listdir(validation_labels_dir) if f.endswith('.txt')])\n",
        "\n",
        "\n",
        "# Check if the number of images and labels match, ensure neither are empty, and verify consistency between image-label pairs.\n",
        "\n",
        "if len(validation_image_files) != len(validation_label_files):\n",
        "    print(\"Warning: Number of images and labels do not match.\")\n",
        "else:\n",
        "    print(\"Validation Dataset is consistent.\")\n",
        "\n",
        "# Quick summary of train set\n",
        "print(f\"Number of validation images: {len(validation_image_files)}\")\n",
        "print(f\"Number of validation labels: {len(validation_label_files)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qF8csvbJf2t",
        "outputId": "e6e96cbd-e69f-44b9-a411-2e5c8f380553"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Dataset is consistent.\n",
            "Number of validation images: 835\n",
            "Number of validation labels: 835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Dataset\n",
        "test_images_dir = os.path.join(dataset_path, 'test/images')\n",
        "test_labels_dir = os.path.join(dataset_path, 'test/labels')\n",
        "\n",
        "# list comprehensions to create a list for storing valid images and labels respectively\n",
        "test_image_files = sorted([f for f in os.listdir(test_images_dir) if f.endswith(('.jpg','.png'))])\n",
        "test_label_files = sorted([f for f in os.listdir(test_labels_dir) if f.endswith('.txt')])\n",
        "\n",
        "\n",
        "# Check if the number of images and labels match, ensure neither are empty, and verify consistency between image-label pairs.\n",
        "\n",
        "if len(test_image_files) != len(test_label_files):\n",
        "    print(\"Warning: Number of images and labels do not match.\")\n",
        "else:\n",
        "    print(\"test Dataset is consistent.\")\n",
        "\n",
        "# Quick summary of train set\n",
        "print(f\"Number of test images: {len(test_image_files)}\")\n",
        "print(f\"Number of test labels: {len(test_label_files)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EmCStyEKVjE",
        "outputId": "5f127300-6e96-43e3-b46d-255d9f08511e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test Dataset is consistent.\n",
            "Number of test images: 841\n",
            "Number of test labels: 841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comprehensive overview Dataset"
      ],
      "metadata": {
        "id": "Xh9IF6UGdQNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get the image size, bbx details from annotations\n",
        "\n",
        "def get_image_and_bboxes_info(image_file, label_file, images_dir, labels_dir):\n",
        "    #Read the image to get the size(w,h)\n",
        "    image_path = os.path.join(images_dir, image_file)\n",
        "    image = cv2.imread(image_path)\n",
        "    image_height, image_width = image.shape[:2]\n",
        "\n",
        "    # Initialize bounding box count and size details\n",
        "    bbox_count = 0\n",
        "    bbox_widths = []\n",
        "    bbox_heights = []\n",
        "\n",
        "    # Read the annotation file to get the bounding boxes\n",
        "    label_path = os.path.join(labels_dir, label_file)\n",
        "    with open(label_path, 'r') as f:\n",
        "        annotations = f.readlines()\n",
        "\n",
        "    for annotation in annotations:\n",
        "        class_id, x_center,y_center, bbox_width, bbox_height = map(float, annotation.split())\n",
        "        # Count bounding boxes and store width/height\n",
        "        bbox_count += 1\n",
        "        bbox_widths.append(bbox_width)\n",
        "        bbox_heights.append(bbox_height)\n",
        "    return image_file, image_width, image_height, bbox_count, bbox_widths, bbox_heights\n",
        "\n",
        "# Function to create the dataframe for a given subset (train, valid, test)\n",
        "\n",
        "def create_subset_dataframe(image_files, label_files, images_dir, labels_dir):\n",
        "    data = []\n",
        "    for image_file, label_file in zip(image_files, label_files):\n",
        "        image_info = get_image_and_bboxes_info(image_file, label_file, images_dir, labels_dir)\n",
        "        data.append(image_info)\n",
        "\n",
        "   # Create dataframe with columns: filename, width, height, bbox_count, avg_bbox_width, avg_bbox_height\n",
        "    df = pd.DataFrame(data, columns=[\n",
        "        'filename', 'image_width', 'image_height', 'bbox_count', 'bbox_widths', 'bbox_heights'\n",
        "    ])\n",
        "    # Calculate average bounding box size for each image\n",
        "    df['avg_bbox_width'] = df['bbox_widths'].apply(lambda x: sum(x) / len(x) if len(x) > 0 else 0)\n",
        "    df['avg_bbox_height'] = df['bbox_heights'].apply(lambda x: sum(x) / len(x) if len(x) > 0 else 0)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "S0yd7ZnLdfmw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = create_subset_dataframe(train_image_files, train_label_files, train_images_dir, train_labels_dir)\n"
      ],
      "metadata": {
        "id": "P4FvtZPbvaww"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_image_files))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21NYR1Wp2vcU",
        "outputId": "ef00f8f5-1b02-4911-98a8-ff2ce58546bf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Dataset:\")\n",
        "print(train_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRGTCyaW24Ot",
        "outputId": "44e00f47-e7d3-4598-9669-e1ccac6216b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "                                            filename  image_width  \\\n",
            "0  0_wny3n8ot_jpg.rf.1f2df7789afda614056522ea95e8...          640   \n",
            "1  0_wny3n8ot_jpg.rf.2e107e048b63fdfabebb0e69def3...          640   \n",
            "2  0_wny3n8ot_jpg.rf.a686302d18f8466853f7c8cfd830...          640   \n",
            "3  2021_04_07_19_24_6328_2021_04_07_Ulnar_Fractur...          640   \n",
            "4  2021_04_07_19_24_6328_2021_04_07_Ulnar_Fractur...          640   \n",
            "\n",
            "   image_height  bbox_count               bbox_widths            bbox_heights  \\\n",
            "0           640           1              [0.20859375]            [0.12890625]   \n",
            "1           640           1               [0.1421875]              [0.215625]   \n",
            "2           640           1               [0.1578125]             [0.2234375]   \n",
            "3           640           2  [0.16796875, 0.16796875]  [0.2140625, 0.1578125]   \n",
            "4           640           2        [0.19375, 0.19375]  [0.2328125, 0.1859375]   \n",
            "\n",
            "   avg_bbox_width  avg_bbox_height  \n",
            "0        0.208594         0.128906  \n",
            "1        0.142187         0.215625  \n",
            "2        0.157812         0.223438  \n",
            "3        0.167969         0.185937  \n",
            "4        0.193750         0.209375  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Display the DataFrame in table format\n",
        "print(\"Train Dataset:\")\n",
        "print(tabulate(train_df.tail(5), headers='keys', tablefmt='pretty'))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PybcHQtB3TjG",
        "outputId": "7712426e-dfa1-4ff8-b20f-f0048bacc76b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "+------+------------------------------------------------------------------------------------------------+-------------+--------------+------------+--------------+--------------+----------------+-----------------+\n",
            "|      |                                            filename                                            | image_width | image_height | bbox_count | bbox_widths  | bbox_heights | avg_bbox_width | avg_bbox_height |\n",
            "+------+------------------------------------------------------------------------------------------------+-------------+--------------+------------+--------------+--------------+----------------+-----------------+\n",
            "| 3774 | xray-of-a-hand-of-a-patient-showing-fractured-bone_jpg.rf.7a9f1d579488d1994d32cce9cfa2bee4.jpg |     640     |     640      |     1      | [0.05859375] | [0.1265625]  |   0.05859375   |    0.1265625    |\n",
            "| 3775 | xray-of-a-hand-of-a-patient-showing-fractured-bone_jpg.rf.c45694260f8f5b8ad7db7cee4d474d2a.jpg |     640     |     640      |     1      | [0.1328125]  |  [0.08125]   |   0.1328125    |     0.08125     |\n",
            "| 3776 |                        xray_jpg.rf.50d5811666104edcd2be21af25f2321d.jpg                        |     640     |     640      |     1      | [0.7859375]  |    [1.0]     |   0.7859375    |       1.0       |\n",
            "| 3777 |                        xray_jpg.rf.7c67fe9fbd1c7a75b1e6da0be9856a84.jpg                        |     640     |     640      |     1      |    [1.0]     |  [0.890625]  |      1.0       |    0.890625     |\n",
            "| 3778 |                        xray_jpg.rf.9a58bed2e60c6fa206a8b8f7e52c323d.jpg                        |     640     |     640      |     1      |  [0.86875]   |    [1.0]     |    0.86875     |       1.0       |\n",
            "+------+------------------------------------------------------------------------------------------------+-------------+--------------+------------+--------------+--------------+----------------+-----------------+\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM9Np6DTa/SD48VgOkCBisG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}